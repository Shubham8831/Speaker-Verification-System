{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15b915a",
   "metadata": {},
   "source": [
    "### 1. Loading Dataset\n",
    "- I have taked data of audio from website : https://commonvoice.mozilla.org/en/datasets and version : Common Voice Delta Segment 19.0\n",
    "- downloaded it -> unzip it and saved it in -> data/all_audio_data \n",
    "- downloaded data has a file \"validated.tsv\" that contains 2 imp. data 'client_id' , 'path(file name)' of the audio and all other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8947691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49de062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137 entries, 0 to 136\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   client_id        137 non-null    object \n",
      " 1   path             137 non-null    object \n",
      " 2   sentence_id      137 non-null    object \n",
      " 3   sentence         137 non-null    object \n",
      " 4   sentence_domain  1 non-null      object \n",
      " 5   up_votes         137 non-null    int64  \n",
      " 6   down_votes       137 non-null    int64  \n",
      " 7   age              117 non-null    object \n",
      " 8   gender           91 non-null     object \n",
      " 9   accents          136 non-null    object \n",
      " 10  variant          0 non-null      float64\n",
      " 11  locale           137 non-null    object \n",
      " 12  segment          0 non-null      float64\n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# loading validated.tsv into a pandas dataframe\n",
    "df = pd.read_csv(r\"C:\\Users\\shubu\\Desktop\\Speaker Verification System\\data\\validated.tsv\", sep=\"\\t\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a95970",
   "metadata": {},
   "source": [
    "- since we need some target data and non target data to train out model \n",
    "- so we find a client_id with most numbers of data/audio to make it a reference audio to train model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8776880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id\n",
      "b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467d52e816db909dbe2be05b8ea36a4bca91179503817a1b093a9e6036abb514c6ad1aaf1ffa71b3d32ce    28\n",
      "60420cbff86f4f0a421e0f797a5b263ed86e12b0d504f47f0f2cfafd2728b30364575c58f6194feb4c777221e426723c9c70b52f267c0d52ae64bcd61d3ee9cf    20\n",
      "64682a2154ab6c1f1179cca7deb92457947174c2f45db0f3f30acfac052f98ac1ef71f780a721c76f86e958b35cae92296cb7bf0c2414ea73342a00a48854942    15\n",
      "e8e299ceb26b0e13b890a83f6e2aa8c464520fe1271a4ab4f4e853f296d4c70c50f829f7bd0eae70d82b1f9b93f432c70682122db4fb7427c802ff11ceba0fd5     8\n",
      "6fb7fe81a15e5e14ea771b047a81a786203287eabe7d4f2d616a2f51d329704516c327d7a30c761d38016d708da9365466cab653ea6d02ab16c47def9936f1ef     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df[\"client_id\"].value_counts() # finds the number of rows of client id\n",
    "\n",
    "print(counts.head(5)) # Print top 5 most-frequent client id values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1714d8",
   "metadata": {},
   "source": [
    "- we see that client_id = b87.. has 28 audios wich can be used as training data for target speaker(reference audio)\n",
    "- so now we make a new data frame for the 'target speaker' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80a050b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of target clips: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_domain</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...</td>\n",
       "      <td>common_voice_en_40882518.mp3</td>\n",
       "      <td>ee9b750a4e08de54ce5742ba8bbeaf8209a10a9f5cc882...</td>\n",
       "      <td>The district had its origins in the Ware Rural...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>Canadian English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...</td>\n",
       "      <td>common_voice_en_40903624.mp3</td>\n",
       "      <td>eec76b5d373cada19063f29ab4d9ee73988d6fef4ec7e5...</td>\n",
       "      <td>Yet fortune would soon turn on the Grey househ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>Canadian English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...</td>\n",
       "      <td>common_voice_en_40903655.mp3</td>\n",
       "      <td>eec10bab785aa378caa2cfe5feb123a00a372b98bf527c...</td>\n",
       "      <td>He was an enigmatic figure for most of his car...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>Canadian English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...</td>\n",
       "      <td>common_voice_en_40923835.mp3</td>\n",
       "      <td>eee3001d454b935f22a8efa974b84b128e1dfbea29e3e0...</td>\n",
       "      <td>Eyes are small.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>Canadian English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...</td>\n",
       "      <td>common_voice_en_40924027.mp3</td>\n",
       "      <td>ef1bd2150466b7242c84ec70ae390b37267e4fb859a201...</td>\n",
       "      <td>Lloyd was born in Glasgow, Scotland.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>Canadian English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             client_id  \\\n",
       "109  b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...   \n",
       "110  b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...   \n",
       "111  b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...   \n",
       "112  b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...   \n",
       "113  b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467...   \n",
       "\n",
       "                             path  \\\n",
       "109  common_voice_en_40882518.mp3   \n",
       "110  common_voice_en_40903624.mp3   \n",
       "111  common_voice_en_40903655.mp3   \n",
       "112  common_voice_en_40923835.mp3   \n",
       "113  common_voice_en_40924027.mp3   \n",
       "\n",
       "                                           sentence_id  \\\n",
       "109  ee9b750a4e08de54ce5742ba8bbeaf8209a10a9f5cc882...   \n",
       "110  eec76b5d373cada19063f29ab4d9ee73988d6fef4ec7e5...   \n",
       "111  eec10bab785aa378caa2cfe5feb123a00a372b98bf527c...   \n",
       "112  eee3001d454b935f22a8efa974b84b128e1dfbea29e3e0...   \n",
       "113  ef1bd2150466b7242c84ec70ae390b37267e4fb859a201...   \n",
       "\n",
       "                                              sentence sentence_domain  \\\n",
       "109  The district had its origins in the Ware Rural...             NaN   \n",
       "110  Yet fortune would soon turn on the Grey househ...             NaN   \n",
       "111  He was an enigmatic figure for most of his car...             NaN   \n",
       "112                                    Eyes are small.             NaN   \n",
       "113               Lloyd was born in Glasgow, Scotland.             NaN   \n",
       "\n",
       "     up_votes  down_votes       age          gender           accents  \\\n",
       "109         2           0  thirties  male_masculine  Canadian English   \n",
       "110         2           0  thirties  male_masculine  Canadian English   \n",
       "111         2           0  thirties  male_masculine  Canadian English   \n",
       "112         2           0  thirties  male_masculine  Canadian English   \n",
       "113         2           0  thirties  male_masculine  Canadian English   \n",
       "\n",
       "     variant locale  segment  \n",
       "109      NaN     en      NaN  \n",
       "110      NaN     en      NaN  \n",
       "111      NaN     en      NaN  \n",
       "112      NaN     en      NaN  \n",
       "113      NaN     en      NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  we choose client id with 28 clips : we will use this as target speaker training data\n",
    "target_id = \"b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467d52e816db909dbe2be05b8ea36a4bca91179503817a1b093a9e6036abb514c6ad1aaf1ffa71b3d32ce\"\n",
    "\n",
    "# makiing new data frame\n",
    "df_target = df[df[\"client_id\"] == target_id].copy()\n",
    "\n",
    "print(f\"no. of target clips: {len(df_target)}\") \n",
    "df_target.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0567b",
   "metadata": {},
   "source": [
    "- we also need the data for 'non-target speaker' values for training so, we randomly select 40 rows from the 'df' and make a new dataframe  'df_non_target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5747b9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-target clips: 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_domain</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64682a2154ab6c1f1179cca7deb92457947174c2f45db0...</td>\n",
       "      <td>common_voice_en_41113888.mp3</td>\n",
       "      <td>f0c37c28e0761e07163b8c9893ed039c789de7f4feba64...</td>\n",
       "      <td>As the popularity of bridging loans increased,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>United States English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b895602d9eae132fe68b85ff4a1af9d377f0f324686c25...</td>\n",
       "      <td>common_voice_en_41069015.mp3</td>\n",
       "      <td>f07b5c4c8d545f5d76281f14b1dbad58e73f637ca1d6ad...</td>\n",
       "      <td>The historicity of Samyogita is a matter of de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38a6ab913e27c72c3f28f3d2da65caa00933288bfaaa24...</td>\n",
       "      <td>common_voice_en_40983032.mp3</td>\n",
       "      <td>efe4e03f95b62047b25b5cadab7793fd1e517ea9fbac73...</td>\n",
       "      <td>On Sundays, four trains run each way, to Carli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India and South Asia (India, Pakistan, Sri Lanka)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64682a2154ab6c1f1179cca7deb92457947174c2f45db0...</td>\n",
       "      <td>common_voice_en_41118674.mp3</td>\n",
       "      <td>f0f4a3700c9a630321b7cc89f8c9265f2e827d09eaa801...</td>\n",
       "      <td>He was a university student in both cities and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female_feminine</td>\n",
       "      <td>United States English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6fb7fe81a15e5e14ea771b047a81a786203287eabe7d4f...</td>\n",
       "      <td>common_voice_en_40960881.mp3</td>\n",
       "      <td>efa1cddc7d5e9e6c6673b052376d371d7469ec42386ea1...</td>\n",
       "      <td>Both the blue and white jerseys featured red s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  64682a2154ab6c1f1179cca7deb92457947174c2f45db0...   \n",
       "1  b895602d9eae132fe68b85ff4a1af9d377f0f324686c25...   \n",
       "2  38a6ab913e27c72c3f28f3d2da65caa00933288bfaaa24...   \n",
       "3  64682a2154ab6c1f1179cca7deb92457947174c2f45db0...   \n",
       "4  6fb7fe81a15e5e14ea771b047a81a786203287eabe7d4f...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_en_41113888.mp3   \n",
       "1  common_voice_en_41069015.mp3   \n",
       "2  common_voice_en_40983032.mp3   \n",
       "3  common_voice_en_41118674.mp3   \n",
       "4  common_voice_en_40960881.mp3   \n",
       "\n",
       "                                         sentence_id  \\\n",
       "0  f0c37c28e0761e07163b8c9893ed039c789de7f4feba64...   \n",
       "1  f07b5c4c8d545f5d76281f14b1dbad58e73f637ca1d6ad...   \n",
       "2  efe4e03f95b62047b25b5cadab7793fd1e517ea9fbac73...   \n",
       "3  f0f4a3700c9a630321b7cc89f8c9265f2e827d09eaa801...   \n",
       "4  efa1cddc7d5e9e6c6673b052376d371d7469ec42386ea1...   \n",
       "\n",
       "                                            sentence sentence_domain  \\\n",
       "0  As the popularity of bridging loans increased,...             NaN   \n",
       "1  The historicity of Samyogita is a matter of de...             NaN   \n",
       "2  On Sundays, four trains run each way, to Carli...             NaN   \n",
       "3  He was a university student in both cities and...             NaN   \n",
       "4  Both the blue and white jerseys featured red s...             NaN   \n",
       "\n",
       "   up_votes  down_votes       age           gender  \\\n",
       "0         2           0  twenties  female_feminine   \n",
       "1         2           0  twenties              NaN   \n",
       "2         2           0  twenties              NaN   \n",
       "3         2           0  twenties  female_feminine   \n",
       "4         2           0       NaN              NaN   \n",
       "\n",
       "                                             accents  variant locale  segment  \n",
       "0                              United States English      NaN     en      NaN  \n",
       "1                              United States English      NaN     en      NaN  \n",
       "2  India and South Asia (India, Pakistan, Sri Lanka)      NaN     en      NaN  \n",
       "3                              United States English      NaN     en      NaN  \n",
       "4                              United States English      NaN     en      NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all data except the target speaker data\n",
    "df_non_target_all = df[df[\"client_id\"] != target_id].copy()\n",
    "\n",
    "# randomly selecting 40 audios \n",
    "df_non_target = df_non_target_all.sample(n=40, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of non-target clips: {len(df_non_target)}\")\n",
    "df_non_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519cdf51",
   "metadata": {},
   "source": [
    "- now, we have 2 data frame 'df_target' and 'df_not_target' which contain all the required path for audios that will be used for training the ML model\n",
    "- both data frame has a coulumn 'path' but it has just file name. \n",
    "- so, we will extract those file names and create new column 'full_path' by adding the file path and file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65098757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109    C:\\Users\\shubu\\Desktop\\Speaker Verification Sy...\n",
       "110    C:\\Users\\shubu\\Desktop\\Speaker Verification Sy...\n",
       "111    C:\\Users\\shubu\\Desktop\\Speaker Verification Sy...\n",
       "112    C:\\Users\\shubu\\Desktop\\Speaker Verification Sy...\n",
       "113    C:\\Users\\shubu\\Desktop\\Speaker Verification Sy...\n",
       "Name: full_path, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "CLIPS_DIRECTORY = r\"C:\\Users\\shubu\\Desktop\\Speaker Verification System\\data\\clips\" # folder path with all the audios\n",
    "\n",
    "# creating new column “full_path” with directory and file name : absolute path\n",
    "df_target[\"full_path\"] = df_target[\"path\"].apply(lambda filename: os.path.join(CLIPS_DIRECTORY, filename))\n",
    "df_non_target[\"full_path\"] = df_non_target[\"path\"].apply(lambda filename: os.path.join(CLIPS_DIRECTORY, filename))\n",
    "\n",
    "# df_target[\"full_path\"].head(), df_non_target[\"full_path\"].head() \n",
    "df_target[\"full_path\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfc09d",
   "metadata": {},
   "source": [
    "### 2. for finding MFCC statistics from each audio file\n",
    "- for each audio clip:\n",
    "- load at 16 kHz.\n",
    "- Trim silence\n",
    "- Compute 13 MFCCs (shape = (13, T) for some T frames).\n",
    "- Take the mean and standard deviation of each of the 13 coefficients → that gives us a 26-dim vector (13 means + 13 stds).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a787b",
   "metadata": {},
   "source": [
    "#### MFCC Statistics detail\n",
    "- Seeing sound -> curvy path on paper -> can be thousands of numbers long -> we squeeze all that info. into just few important numbers -> MFCCs help us find those important numbers\n",
    "\n",
    "- Mel‐Frequency Cepstral Coefficients -> a special set of measurements -> We pick 13 of these special measurements -> for every short piece of the sound, we get 13 numbers.\n",
    "\n",
    "- we split the sound into little pieces -> For each tiny piece, we find those 13 MFCC numbers.\n",
    "\n",
    "- we have those 13 numbers for every little chunk -> 100 chunks for a 2‐second audio -> big table -> we don’t keep all 100 rows. Instead, we take average (mean) of these 100 numbers\n",
    "\n",
    "- How much do they jump up and down -> standard deviation\n",
    "\n",
    "- Since there are 13 MFCC measurements, we get 13 “means” and 13 “standard deviations” - > These 26 numbers are the “MFCC statistics” for that entire audio clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45895e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find MFCC statistics\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_RATE = 16000\n",
    "N_MFCC = 13\n",
    "\n",
    "def MFCC_STATISTICS(filepath, sr=SAMPLE_RATE, n_mfcc=N_MFCC):\n",
    "    \n",
    "    wav, _ = librosa.load(filepath, sr=sr)   # load the file at 16 kHz\n",
    "    wav, _ = librosa.effects.trim(wav)       # silence removed\n",
    "    mfcc = librosa.feature.mfcc(y=wav, sr=sr, n_mfcc=n_mfcc)\n",
    "    means = np.mean(mfcc, axis=1)                       \n",
    "    stds  = np.std(mfcc, axis=1)                        \n",
    "    return np.concatenate([means, stds])                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb341b",
   "metadata": {},
   "source": [
    "- now, i loop over all 28 target clips, then all 40 non-target clips\n",
    "- extract their 26-dim feature vectors, and store them in x and make label y (y = 1 for each target clip, y = 0 for each non-target clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82d01306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : (68, 26)\n",
      "Label : (68,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "# target clips (label = 1)\n",
    "for fp in df_target[\"full_path\"]:\n",
    "    vec = MFCC_STATISTICS(fp)\n",
    "    x.append(vec)\n",
    "    y.append(1)\n",
    "\n",
    "# non-target clips (label = 0)\n",
    "for fp in df_non_target[\"full_path\"]:\n",
    "    vec = MFCC_STATISTICS(fp)\n",
    "    x.append(vec)\n",
    "    y.append(0)\n",
    "\n",
    "# convert list to np array\n",
    "x = np.vstack(x)   # shape = (28 + 40, 26)\n",
    "y = np.array(y)    # shape = (68,)\n",
    "print(\"Features :\", x.shape)\n",
    "print(\"Label :\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247f556",
   "metadata": {},
   "source": [
    "### 3. Train_Test_Split\n",
    "- now, we have x and y (input features and output feature data)\n",
    "- so, now we split out data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a5f7a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (54, 26) y_train: (54,)\n",
      "x_test:  (14, 26) y_test:  (14,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size= 0.2, random_state=1, stratify=y)\n",
    "\n",
    "print(\"x_train:\", x_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape, \"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9e8f0",
   "metadata": {},
   "source": [
    "### 4. Model\n",
    "##### We used SVC (Support Vector Classifier): \n",
    "- SVC works well on smaller datasets\n",
    "- after extracting MFCC stats, the data becomes high dimentional\n",
    "- SVC handles high-dimensional data and finds an optimal decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "333e953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True, random_state=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True, random_state=2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel=\"rbf\", probability=True, random_state=2)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49f70c",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a3fcab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857\n",
      "F1-score: 0.7692\n",
      "\n",
      "report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-target       0.86      0.75      0.80         8\n",
      "      target       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.79      0.79      0.78        14\n",
      "weighted avg       0.80      0.79      0.79        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_score  = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\\n\")\n",
    "print(\"report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"non-target\",\"target\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0a06e",
   "metadata": {},
   "source": [
    "### 6. Model Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3cac5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce5942",
   "metadata": {},
   "source": [
    "### 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a32fb0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: target  (label = 1)\n",
      "Confidence --> non-target: 0.0717,  target: 0.9283\n"
     ]
    }
   ],
   "source": [
    "test_audio_path = r\"C:\\Users\\shubu\\Desktop\\Speaker Verification System\\testing_data\\common_voice_en_40903624.mp3\"  \n",
    "\n",
    "# MFCC statistics \n",
    "features = MFCC_STATISTICS(test_audio_path)       \n",
    "features = features.reshape(1, -1)                \n",
    "\n",
    "# run trained SVC on this example\n",
    "pred_label = clf.predict(features)[0]             \n",
    "pred_probability  = clf.predict_proba(features)[0]        \n",
    "\n",
    "\n",
    "label_map = {0: \"non-target\", 1: \"target\"}\n",
    "pred_text = label_map[pred_label]\n",
    "\n",
    "# result print\n",
    "print(f\"Predicted class: {pred_text}  (label = {pred_label})\")\n",
    "print(f\"Confidence --> non-target: {pred_probability[0]:.4f},  target: {pred_probability[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
